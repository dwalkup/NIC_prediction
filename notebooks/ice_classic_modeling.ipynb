{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nenana Ice Classic Modeling\n",
    "This notebook was used for modeling the NIC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# pipeline and preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from category_encoders import WOEEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import KernelPCA as KPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "# evaluation\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit, cross_validate, cross_val_predict\n",
    "from sklearn import metrics # explained_variance_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "#from sklearn.utils import check_arrays # converts list-like objects to array (if needed)\n",
    "\n",
    "# import datetime # didn't need after all\n",
    "\n",
    "# Pretty Print to make some outputs easier to read\n",
    "import pprint\n",
    "\n",
    "# filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc # garbage collection\n",
    "\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(data):\n",
    "    data = pd.DataFrame(data)\n",
    "    for c in data.columns.tolist():\n",
    "        data[c] = data[c].astype(str)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapsed Cells\n",
    "The cells collapsed below were used to create the 'features_added.csv' data file that is loaded later. They are collapsed because they are commented out and not run. Instead, the file is read into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bryan suggested rolling avg, rolling slope, rolling acceleration, and rolling std dev features might help\n",
    "# improve model performance\n",
    "\n",
    "# def slope(y):\n",
    "#     x = range(len(y))\n",
    "#     # y = mx + b\n",
    "#     m, b = np.polyfit(x, y, 1)\n",
    "#     return m\n",
    "\n",
    "# def accel(y):\n",
    "#     t = range(len(y))\n",
    "#     # y = 1/2 g t^2 + v t + y0\n",
    "#     a, v, y0 = np.polyfit(t, y, 2)\n",
    "#     return 5*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read data\n",
    "# df = pd.read_csv('../data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['winningTime'] = pd.to_datetime(df['winningTime'], errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for ordinal day of year\n",
    "# df['dayOfYear'] = df['Date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create binary 'winningDate' column\n",
    "# df['winningDate'] = 0\n",
    "# idx = df.loc[df['winningTime'] != '0'].index\n",
    "# df['winningDate'].loc[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['winningDate'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information for 1995 and 1999 are missing some dates, including the winning date. I decided to drop the data for those years, since there is no target as a result. Survival analysis would also falsely treat those years as censored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_1995_1999 = df.loc[(df['Date'].dt.year == 1995)|(df['Date'].dt.year == 1999)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(index = drop_1995_1999, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all records for a year that are after the ice broke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_list = sorted(list(set(df['Date'].dt.year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(year_list, compact = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get winning date indices\n",
    "# idx_w = df.loc[df['winningDate'] == 1].index\n",
    "# idx_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of indices to drop\n",
    "# drop_index = []\n",
    "# for i, year in enumerate(year_list):\n",
    "#     idx_y = df.loc[df['Date'].dt.year == year].index\n",
    "#     for idx in idx_y:\n",
    "#         if idx > idx_w[i]:\n",
    "#             drop_index.append(idx)\n",
    "#         else:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop observations that occurred after the winning date in a year\n",
    "# for idx in drop_index:\n",
    "#     df.drop(index = idx, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['past'] = (df['Date'] < '2015-01-01').astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['future'] = 1 - df['past']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(3).append(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['precipType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encode precipType\n",
    "# df = df.merge(pd.get_dummies(df['precipType'], prefix = 'precip', drop_first = True, sparse = True),\n",
    "#          how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop precipType after encoding\n",
    "# df.drop(columns = 'precipType', inplace = True)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column for daily average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['temperatureAvg'] = (df['temperatureMin'] + df['temperatureMax']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots showing examples of additional time-series features mentioned above; kept for example/reminder\n",
    "# temp = df['temperatureAvg'].head(90).copy()\n",
    "\n",
    "# temp.plot()\n",
    "# temp.rolling(5).mean().plot()\n",
    "# plt.show()\n",
    "\n",
    "# temp.rolling(5).apply(lambda x: slope(x)).plot()\n",
    "# temp.rolling(10).apply(lambda x: accel(x)).plot()\n",
    "# temp.rolling(10).std().plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns for number of \"hot days,\" \"cold days,\" and snow accumulated since Apr 1 in a given year.\n",
    "\n",
    "I defined a \"hot day\" as a day where: day_average_temp > median(year_avg_temp) + std_dev(year_avg_temp)\n",
    "\n",
    "A \"cold day\" is a day where: day_average_temp < median(year_avg_temp) - std_dev(year_avg_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot_count = []\n",
    "# cold_count = []\n",
    "# daily_accumulation = []\n",
    "# for year in year_list:\n",
    "#     hot_temp_count = 0\n",
    "#     cold_temp_count = 0\n",
    "#     daily_accum = 0\n",
    "#     temp_df = df.loc[df['Date'].dt.year == year]\n",
    "#     hot_threshold = temp_df['temperatureAvg'].median() + temp_df['temperatureAvg'].std()\n",
    "#     cold_threshold = temp_df['temperatureAvg'].median() - temp_df['temperatureAvg'].std()\n",
    "#     for idx in temp_df.index:\n",
    "#         current_temp = temp_df['temperatureAvg'].loc[idx]\n",
    "#         if temp_df['precip_snow'].loc[idx] == 1:\n",
    "#             daily_accum += temp_df['precipAccumulation'].loc[idx]\n",
    "#         else:\n",
    "#             pass\n",
    "#         if current_temp >= hot_threshold:\n",
    "#             hot_temp_count += 1\n",
    "#         elif current_temp <= cold_threshold:\n",
    "#             cold_temp_count += 1\n",
    "#         else:\n",
    "#             pass\n",
    "#         hot_count.append(hot_temp_count)\n",
    "#         cold_count.append(cold_temp_count)\n",
    "#         daily_accumulation.append(daily_accum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['numHotDays'] = hot_count\n",
    "# df['numColdDays'] = cold_count\n",
    "# df['accumulatedSnow'] = daily_accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data before adding rolling average features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/pre-moving-average_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns for moving average features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_cols = ['humidity', 'windSpeed', 'windBearing', 'uvIndex', 'precipIntensity', 'iceThickness', 'temperatureAvg', 'numHotDays', 'numColdDays']\n",
    "# windows = [3, 5, 7, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first add new columns with dummy info\n",
    "# for col in ma_cols:\n",
    "#     for window in windows:\n",
    "#         label_ma = col + '_MA' + str(window)\n",
    "#         df[label_ma] = 0\n",
    "        \n",
    "#         label_slope = col + '_MA-slope' + str(window)\n",
    "#         df[label_slope] = 0\n",
    "        \n",
    "#         label_accel = col + '_MA-accel' + str(window)\n",
    "#         df[label_accel] = 0\n",
    "        \n",
    "#         label_std = col + '_MA-std_dev' + str(window)\n",
    "#         df[label_std] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update each year with its rolling averages\n",
    "# %time\n",
    "# for year in year_list:\n",
    "#     temp_df = df.loc[df['Date'].dt.year == year]\n",
    "#     for col in ma_cols:\n",
    "#         for window in windows:\n",
    "#             # assign labels\n",
    "#             label_ma = col + '_MA' + str(window)\n",
    "#             label_slope = col + '_MA-slope' + str(window)\n",
    "#             label_accel = col + '_MA-accel' + str(window)\n",
    "#             label_std = col + '_MA-std_dev' + str(window)\n",
    "#             # for each year, update row values in new columns\n",
    "#             for idx in temp_df.index:\n",
    "#                 df[label_ma].loc[idx] = temp_df[col].rolling(window).mean().loc[idx]\n",
    "#                 df[label_slope].loc[idx] = temp_df[col].rolling(window).apply(lambda x: slope(x)).loc[idx]\n",
    "#                 df[label_accel].loc[idx] = temp_df[col].rolling(window).apply(lambda x: accel(x)).loc[idx]\n",
    "#                 df[label_std].loc[idx] = temp_df[col].rolling(window).std().loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/features_added.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read results from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/features_added.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>moonPhase</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipAccumulation</th>\n",
       "      <th>...</th>\n",
       "      <th>numColdDays_MA-accel5</th>\n",
       "      <th>numColdDays_MA-std_dev5</th>\n",
       "      <th>numColdDays_MA7</th>\n",
       "      <th>numColdDays_MA-slope7</th>\n",
       "      <th>numColdDays_MA-accel7</th>\n",
       "      <th>numColdDays_MA-std_dev7</th>\n",
       "      <th>numColdDays_MA10</th>\n",
       "      <th>numColdDays_MA-slope10</th>\n",
       "      <th>numColdDays_MA-accel10</th>\n",
       "      <th>numColdDays_MA-std_dev10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989-03-01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.42</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.58</td>\n",
       "      <td>29.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989-03-02</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.68</td>\n",
       "      <td>8.59</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.38</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989-03-03</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.84</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-19.23</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989-03-04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2.52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.34</td>\n",
       "      <td>4.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989-03-05</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.76</td>\n",
       "      <td>216.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-38.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.30384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  moonPhase  humidity  windSpeed  windBearing  uvIndex  \\\n",
       "0  1989-03-01       0.80      0.70       8.42        236.0      1.0   \n",
       "1  1989-03-02       0.83      0.68       8.59        266.0      1.0   \n",
       "2  1989-03-03       0.87      0.50       5.84        344.0      1.0   \n",
       "3  1989-03-04       0.90      0.51       2.52          6.0      1.0   \n",
       "4  1989-03-05       0.94      0.56       1.76        216.0      1.0   \n",
       "\n",
       "   temperatureMin  temperatureMax  precipIntensity  precipAccumulation  ...  \\\n",
       "0           20.58           29.65              0.0                 0.0  ...   \n",
       "1           -7.38           29.07              0.0                 0.0  ...   \n",
       "2          -19.23            1.84              0.0                 0.0  ...   \n",
       "3          -30.34            4.69              0.0                 0.0  ...   \n",
       "4          -38.53            0.74              0.0                 0.0  ...   \n",
       "\n",
       "  numColdDays_MA-accel5  numColdDays_MA-std_dev5  numColdDays_MA7  \\\n",
       "0                   NaN                      NaN              NaN   \n",
       "1                   NaN                      NaN              NaN   \n",
       "2                   NaN                      NaN              NaN   \n",
       "3                   NaN                      NaN              NaN   \n",
       "4              0.714286                  1.30384              NaN   \n",
       "\n",
       "   numColdDays_MA-slope7  numColdDays_MA-accel7  numColdDays_MA-std_dev7  \\\n",
       "0                    NaN                    NaN                      NaN   \n",
       "1                    NaN                    NaN                      NaN   \n",
       "2                    NaN                    NaN                      NaN   \n",
       "3                    NaN                    NaN                      NaN   \n",
       "4                    NaN                    NaN                      NaN   \n",
       "\n",
       "   numColdDays_MA10  numColdDays_MA-slope10  numColdDays_MA-accel10  \\\n",
       "0               NaN                     NaN                     NaN   \n",
       "1               NaN                     NaN                     NaN   \n",
       "2               NaN                     NaN                     NaN   \n",
       "3               NaN                     NaN                     NaN   \n",
       "4               NaN                     NaN                     NaN   \n",
       "\n",
       "   numColdDays_MA-std_dev10  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How good does my model have to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-events:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9827072152653548"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the thing to beat: 0.9827072152653548\n",
    "print('Percentage of non-events:')\n",
    "1 - (df['winningDate'].sum()/df['winningDate'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns that are highly correlated\n",
    "* temperatureMin and temperatureMax information was captured in temperatureAvg\n",
    "* precipAccumulation information was captured in accumulatedSnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['temperatureMin', 'temperatureMax', 'precipAccumulation'],\n",
    "        inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training and testing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df['past'] == 1]\n",
    "train.drop(columns = ['past', 'future'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1399 entries, 0 to 1398\n",
      "Columns: 162 entries, Date to numColdDays_MA-std_dev10\n",
      "dtypes: float64(154), int64(6), object(2)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[df['future'] == 1]\n",
    "test.drop(columns = ['past', 'future'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 278 entries, 1399 to 1676\n",
      "Columns: 162 entries, Date to numColdDays_MA-std_dev10\n",
      "dtypes: float64(154), int64(6), object(2)\n",
      "memory usage: 354.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['past', 'future'], inplace = True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame to track model performance\n",
    "Eventually I'm going to get around to automating scoring tracking..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring_tracker = pd.DataFrame(columns = ['Model', 'Accuracy', 'ROC_AUC',\n",
    "#                                           'F1', 'F1 (weighted)',\n",
    "#                                           'Precision', 'Precision (weighted)',\n",
    "#                                           'Recall', 'Recall (weighted)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to exclude from models (dates and target info)\n",
    "exclude = ['winningTime', 'winningDate',  'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = [c for c in train.columns if c not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ma_cols = [c for c in df.columns.tolist() if not c.endswith(('3', '5', '7', '10'))]\n",
    "used_no_ma_cols = [c for c in no_ma_cols if c not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date',\n",
      " 'moonPhase',\n",
      " 'humidity',\n",
      " 'windSpeed',\n",
      " 'windBearing',\n",
      " 'uvIndex',\n",
      " 'precipIntensity',\n",
      " 'winningTime',\n",
      " 'daylightHours',\n",
      " 'iceThickness',\n",
      " 'dayOfYear',\n",
      " 'winningDate',\n",
      " 'precip_rain',\n",
      " 'precip_snow',\n",
      " 'temperatureAvg',\n",
      " 'numHotDays',\n",
      " 'numColdDays',\n",
      " 'accumulatedSnow']\n",
      "['moonPhase',\n",
      " 'humidity',\n",
      " 'windSpeed',\n",
      " 'windBearing',\n",
      " 'uvIndex',\n",
      " 'precipIntensity',\n",
      " 'daylightHours',\n",
      " 'iceThickness',\n",
      " 'dayOfYear',\n",
      " 'precip_rain',\n",
      " 'precip_snow',\n",
      " 'temperatureAvg',\n",
      " 'numHotDays',\n",
      " 'numColdDays',\n",
      " 'accumulatedSnow']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(no_ma_cols)\n",
    "pprint.pprint(used_no_ma_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notes/Ideas_\n",
    "* ~~add feature for day-of-year (to make the models time-aware);~~\n",
    "* try hidden Markov model;\n",
    "* ~~look at survival analysis/time-to-event analysis;~~\n",
    "* look for outliers in training data, if removed, does model performance improve?;\n",
    "* is there any way to identify mechanical failure of ice vs mush-out?;\n",
    "* more time-series-like features, for instance number of \"hot\" days vs number of \"cold\" days; lags and rolling averages that Bryan talked about\n",
    "* consider under- or over-sampling\n",
    "* try random forest model;\n",
    "* try knn model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
